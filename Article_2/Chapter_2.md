# Chapter 2: Agents Using LangGraph


What if you just want a quick way to spin up a fully working agent? Thatâ€™s where LangGraphâ€™s prebuilt helpers come in.

---

### âš¡ create_react_agent

LangGraph ships with a ready-to-use factory method:
```
from langgraph.prebuilt import create_react_agent
```
This creates an agent powered by the ReAct framework (Reason + Act). In simple terms:  
- **Reason** â†’ the LLM decides what to do.  
- **Act** â†’ it either calls a tool, or responds to the user.

---

### ğŸ›  Parameters

- **llm** â†’ The language model to use (e.g., ChatGoogleGenerativeAI, ChatOpenAI).
- **tools** â†’ List of tools the agent can call. Can be empty if you just want reasoning.
- **state_schema (optional)** â†’ Define custom state structure. Defaults to a simple dict.

ğŸ“Œ Reference: [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)

---

### ğŸ§© Super Short Example

Hereâ€™s the smallest possible agent using create_react_agent.  
We wonâ€™t add tools yet â€” just show reasoning + response.

```
# Install dependencies first:
# pip install -qU langchain langgraph langchain-google-genai

from langchain_google_genai import ChatGoogleGenerativeAI
from langgraph.prebuilt import create_react_agent

# âœ… Setup LLM (using your Google API key)
llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash", api_key="YOUR_API_KEY")

# âœ… Create an agent with no tools
agent = create_react_agent(llm, tools=[])

# âœ… Run the agent manually
response = agent.invoke({"messages": [("user", "Explain LangGraph in one sentence.") ]})
print(response["messages"][-1].content)
```

---

#### ğŸ” Output:

The agent will generate a concise explanation of LangGraph â€” reasoning internally, then responding.

---

### ğŸ¯ Why This Matters

- Fastest way to spin up a thinking agent.
- Great starting point before adding tools, custom nodes, or complex workflows.
- Integrates seamlessly with LangGraph graphs â€” you can drop this agent in as a node.

---
