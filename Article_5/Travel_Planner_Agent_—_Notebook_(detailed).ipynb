{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jc4IP0KkXDPq"
      },
      "source": [
        "# Goal\n",
        "\n",
        "### Make a conversational Travel Planner that remembers user preferences across turns:\n",
        "\n",
        "“I like vegetarian food.”\n",
        "\n",
        "“Keep it budget-friendly.”\n",
        "\n",
        "“Recommend me a 5-day trip.”\n",
        "\n",
        "### We use:\n",
        "\n",
        "#### -> Google Gemini LLM via langchain_google_genai.\n",
        "#### -> LangGraph for graph orchestration\n",
        "#### -> LangChain ConversationSummaryMemory for compact short-term memory\n",
        "#### -> create_react_agent (LangGraph prebuilt) for the agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxiJksCKXYAG"
      },
      "source": [
        "Step 1 — Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shr1vph8XMyM",
        "outputId": "8ffcfffc-af42-4e0a-9cde-cf0d6b1420a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.0/444.0 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Run once in Colab / Jupyter\n",
        "!pip install -qU langchain langgraph langchain-google-genai pydantic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFnMDRn1Xd5M"
      },
      "source": [
        "Step 2 — Set your Google API key securely"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oez3nSmIXg-m"
      },
      "outputs": [],
      "source": [
        "# In Colab use getpass() to avoid storing key in notebook outputs\n",
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "#key = getpass(\"Paste your Google AI Studio API key (hidden): \")\n",
        "#os.environ[\"GOOGLE_API_KEY\"] = key.strip()\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"]=\"AIzaSyBEhOoTh2Iu2UzC1p8Kfz8pL4FxGQP1F_w\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rttbxNK-XqKe"
      },
      "source": [
        "Setp 3 — Imports & helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Oei8IThFXtXR"
      },
      "outputs": [],
      "source": [
        "import os, json, time, re\n",
        "from typing import Dict, Any\n",
        "from getpass import getpass\n",
        "\n",
        "# LangChain / LangGraph imports\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# Memory import\n",
        "from langchain.memory import ConversationSummaryMemory\n",
        "\n",
        "# Small helper to safely extract generated text from different response shapes\n",
        "def extract_text_from_resp(resp: Any) -> str:\n",
        "    # resp may be dict with \"messages\" (list-like) or \"output\"\n",
        "    try:\n",
        "        if isinstance(resp, dict):\n",
        "            if \"messages\" in resp and resp[\"messages\"]:\n",
        "                # support both tuple and object-like messages\n",
        "                last = resp[\"messages\"][-1]\n",
        "                # try attribute access (for objects)\n",
        "                content = getattr(last, \"content\", None) if not isinstance(last, tuple) else None\n",
        "                if not content:\n",
        "                    # tuple like (\"user\", \"text\") or dict with content\n",
        "                    if isinstance(last, tuple) and len(last) >= 2:\n",
        "                        return str(last[1])\n",
        "                    if isinstance(last, dict) and \"content\" in last:\n",
        "                        return str(last[\"content\"])\n",
        "                else:\n",
        "                    return str(content)\n",
        "            if \"output\" in resp and resp[\"output\"]:\n",
        "                return str(resp[\"output\"])\n",
        "        return str(resp)\n",
        "    except Exception:\n",
        "        return str(resp)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOii0cY0XvbA"
      },
      "source": [
        "Step 4 — Define state shape and explain persistence approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PoWFDz2eXu3s"
      },
      "outputs": [],
      "source": [
        "# We'll use a dict-based state to keep node code simple in the notebook.\n",
        "# If you prefer Pydantic models for validation, see the note after the notebook.\n",
        "\n",
        "# State fields we'll use:\n",
        "# - user_message: latest user input\n",
        "# - conversation_summary: summary string produced by ConversationSummaryMemory\n",
        "# - itinerary: agent-produced itinerary\n",
        "# - trace: list of dicts with simple trace info\n",
        "\n",
        "# To persist memory across sessions, we store conversation_summary inside the state and\n",
        "# optionally write it to disk (JSON) at the end of the run.\n",
        "\n",
        "initial_state = {\n",
        "    \"user_message\": None,\n",
        "    \"conversation_summary\": \"\",   # load from disk if you persisted previously\n",
        "    \"itinerary\": None,\n",
        "    \"trace\": []\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTDmeo7OX3sO"
      },
      "source": [
        "Step 5 — Initialize LLM, Memory, Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TaPgYGv5X6mg"
      },
      "outputs": [],
      "source": [
        "# Initialize Gemini via LangChain wrapper\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    google_api_key=os.environ.get(\"GOOGLE_API_KEY\"),\n",
        "    temperature=0.0\n",
        ")\n",
        "\n",
        "# ConversationSummaryMemory uses the LLM to produce compact summaries\n",
        "conv_memory = ConversationSummaryMemory(llm=llm)  # default behavior; you can tune params\n",
        "\n",
        "# Create a single \"planner\" agent (ReAct style) that can think & act.\n",
        "# No external tools needed for this simple flow.\n",
        "planner_agent = create_react_agent(\n",
        "    model=llm,\n",
        "    tools=[],  # no tools required for this tutorial\n",
        "    prompt=(\n",
        "        \"You are a Travel Planner assistant. Use any conversation summary provided \"\n",
        "        \"to remember user preferences. If the user asks for an itinerary, produce \"\n",
        "        \"a 5-day sample plan tailored to their preferences.\"\n",
        "    )\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuCMpr9hYBUk"
      },
      "source": [
        "Step 6 — Node function: planner_node (reads memory, calls agent, updates memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VREgF6BdYClb"
      },
      "outputs": [],
      "source": [
        "def planner_node(state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Node responsibilities:\n",
        "    - Read the existing conversation summary (state['conversation_summary'])\n",
        "    - Build a prompt combining the summary and the new user message\n",
        "    - Call planner_agent\n",
        "    - Update state['itinerary'] with the agent response\n",
        "    - Save the new interaction to ConversationSummaryMemory\n",
        "    - Update state['conversation_summary'] from memory (so the graph state holds the latest)\n",
        "    - Append to state['trace'] for observability\n",
        "    \"\"\"\n",
        "    start = time.time()\n",
        "\n",
        "    user_message = state.get(\"user_message\", \"\") or \"\"\n",
        "    prev_summary = state.get(\"conversation_summary\", \"\") or \"\"\n",
        "\n",
        "    # Build a clear prompt that includes the summary and the new user message\n",
        "    prompt = (\n",
        "        \"Conversation summary (what I've learned about the user so far):\\n\"\n",
        "        f\"{prev_summary}\\n\\n\"\n",
        "        \"New user message:\\n\"\n",
        "        f\"{user_message}\\n\\n\"\n",
        "        \"Task: If the user asks for recommendations or an itinerary, \"\n",
        "        \"use the summary to honor preferences (diet, budget, etc). \"\n",
        "        \"Produce a concise 5-day sample itinerary if requested.\"\n",
        "    )\n",
        "\n",
        "    # Call the planner agent (ReAct prebuilt). Provide messages in a dictionary wrapper.\n",
        "    resp = planner_agent.invoke({\"messages\": [(\"user\", prompt)]})\n",
        "    generated_text = extract_text_from_resp(resp).strip()\n",
        "\n",
        "    # Save to memory (ConversationSummaryMemory expects input/output pair)\n",
        "    try:\n",
        "        conv_memory.save_context({\"input\": user_message}, {\"output\": generated_text})\n",
        "    except Exception as e:\n",
        "        # memory save errors shouldn't crash the node; record trace\n",
        "        generated_text += f\"\\n\\n[MEMORY_SAVE_ERROR: {e}]\"\n",
        "\n",
        "    # Update conversation_summary in state so the graph persists it\n",
        "    try:\n",
        "        mem_vars = conv_memory.load_memory_variables({})\n",
        "        new_summary = mem_vars.get(\"history\", \"\") if isinstance(mem_vars, dict) else str(mem_vars)\n",
        "    except Exception:\n",
        "        new_summary = prev_summary  # fallback to previous summary if memory read fails\n",
        "\n",
        "    # Update state\n",
        "    trace = state.get(\"trace\", [])\n",
        "    trace.append({\n",
        "        \"node\": \"planner\",\n",
        "        \"time\": time.time(),\n",
        "        \"duration\": time.time() - start,\n",
        "        \"raw_output\": generated_text[:800]\n",
        "    })\n",
        "\n",
        "    return {\n",
        "        \"itinerary\": generated_text,\n",
        "        \"conversation_summary\": new_summary,\n",
        "        \"trace\": trace\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "en6XURfyYEO-"
      },
      "source": [
        "Step 7 — Build the LangGraph graph and compile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wG6_lS4UYHpC",
        "outputId": "790b548f-6b1b-4e64-c9eb-c4400c8425e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Graph compiled — planner node ready.\n"
          ]
        }
      ],
      "source": [
        "# Build simple one-node graph: START -> planner -> END\n",
        "graph = StateGraph(dict)   # use dict for simplicity in notebook\n",
        "graph.add_node(\"planner\", planner_node)\n",
        "graph.add_edge(START, \"planner\")\n",
        "graph.add_edge(\"planner\", END)\n",
        "\n",
        "app = graph.compile()\n",
        "print(\"Graph compiled — planner node ready.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrNCtKuWYKUc"
      },
      "source": [
        "Step 8 — Run: Multi-turn conversation (simulate the three inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAoQzJ2LYM_G",
        "outputId": "5e838458-ec9c-4efd-8f8a-f459dbc29453"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- After Turn 1 ---\n",
            "Itinerary (partial):\n",
            " Great, I've noted that you prefer vegetarian food! I'll keep that in mind for any future recommendations or itineraries.\n",
            "Summary:\n",
            " New summary:\n",
            "The human states a preference for vegetarian food, and the AI acknowledges this, noting it for future recommendations or itineraries.\n",
            "Trace entries: 1\n",
            "\n",
            "--- After Turn 2 ---\n",
            "Itinerary (partial):\n",
            " Got it! I've added \"budget-friendly\" to your preferences. So far, I know you prefer:\n",
            "\n",
            "*   **Vegetarian food**\n",
            "*   **Budget-friendly options**\n",
            "\n",
            "I'll keep these in mind for any future recommendations or itineraries!\n",
            "Summary:\n",
            " The human states a preference for vegetarian food, and then adds a request for budget-friendly options. The AI acknowledges both preferences, confirming it will keep them in mind for future recommendations or itineraries.\n",
            "Trace entries: 2\n",
            "\n",
            "--- After Turn 3 (final) ---\n",
            "Final Itinerary:\n",
            " Okay, I can certainly help you plan a 5-day trip! Keeping your preferences for **vegetarian food** and **budget-friendly options** in mind, here's a sample itinerary for a trip to **Prague, Czech Republic**, a city known for its beauty, affordability, and growing vegetarian scene:\n",
            "\n",
            "---\n",
            "\n",
            "### **5-Day Budget-Friendly Vegetarian Trip to Prague**\n",
            "\n",
            "**Accommodation Tip:** Look for hostels or guesthouses in areas like Žižkov or Vinohrady for good value, with easy public transport access to the city center. Consider a multi-day public transport pass upon arrival.\n",
            "\n",
            "**Day 1: Arrival & Old Town Charm**\n",
            "*   **Morning/Afternoon:** Arrive in Prague, check into your accommodation. Take public transport to the city center.\n",
            "*   **Lunch:** Grab a budget-friendly vegetarian \"Smažený sýr\" (fried cheese sandwich) or \"Bramboráky\" (potato pancakes) from a street vendor or a local eatery.\n",
            "*   **Afternoon:** Explore the iconic Old Town Square, marvel at the Astronomical Clock, Týn Church, and St. Nicholas Church. Wander through the charming cobblestone streets.\n",
            "*   **Evening:** Take a romantic stroll across the Charles Bridge at sunset.\n",
            "*   **Dinner:** Find a traditional Czech pub offering vegetarian goulash (often mushroom-based) or a hearty lentil soup. Look for \"vegetariánská jídla\" on menus; many pubs have affordable daily specials.\n",
            "\n",
            "**Day 2: Castle & Lesser Town Wonders**\n",
            "*   **Morning:** Head to the magnificent Prague Castle complex. Explore St. Vitus Cathedral, the Old Royal Palace, St. George's Basilica, and Golden Lane. Enjoy the free areas and panoramic views, or consider a circuit ticket for specific interiors.\n",
            "*   **Lunch:** Descend into Malá Strana (Lesser Town). Find a local café or a \"lahůdky\" (deli) for a vegetarian sandwich, salad, or a cheap and cheerful falafel wrap.\n",
            "*   **Afternoon:** Stroll through the beautiful Wallenstein Garden (free entry) and explore the picturesque streets of Malá Strana. Don't miss the colorful John Lennon Wall.\n",
            "*   **Evening:** Enjoy a budget-friendly dinner at a vegetarian-friendly restaurant in Malá Strana, or cross back to the Old Town. Many Indian or Vietnamese restaurants offer great value vegetarian options.\n",
            "\n",
            "**Day 3: Jewish Quarter & River Views**\n",
            "*   **Morning:** Explore the historic Jewish Quarter (Josefov). Visit the Old Jewish Cemetery, Pinkas Synagogue, and Spanish Synagogue. Consider a combined ticket for better value.\n",
            "*   **Lunch:** Try a delicious and affordable vegetarian bagel or a hearty soup from a small shop in the Jewish Quarter or nearby.\n",
            "*   **Afternoon:** Take a relaxing walk along the Vltava River. Consider a short, inexpensive river cruise for unique city views. Visit the area around the National Theatre.\n",
            "*   **Evening:** Explore the vibrant Wenceslas Square area.\n",
            "*   **Dinner:** Seek out a \"Jídelna\" (canteen-style eatery) for very affordable, often vegetarian-friendly, home-style Czech food. These are excellent for budget travelers.\n",
            "\n",
            "**Day 4: Petřín Hill & Local Flavors**\n",
            "*   **Morning:** Take the funicular up Petřín Hill (use your public transport pass). Enjoy breathtaking panoramic views from the Petřín Lookout Tower (a mini Eiffel Tower). Wander through the rose gardens and visit the Mirror Maze.\n",
            "*   **Lunch:** Pack a picnic with vegetarian sandwiches, fruits, and snacks from a local supermarket to enjoy on Petřín Hill – a great budget saver!\n",
            "*   **Afternoon:** Descend Petřín Hill and explore the charming Kampa Island area, often called \"Prague Venice\" for its canals.\n",
            "*   **Evening:** Venture into a less touristy neighborhood like Vinohrady or Žižkov for dinner. These areas often have more authentic and budget-friendly restaurants with good vegetarian options. Try \"smažený hermelín\" (fried pickled cheese) or a vegetarian pizza.\n",
            "\n",
            "**Day 5: Art, Culture & Departure**\n",
            "*   **Morning:** Visit a museum or gallery that interests you. Options include the National Museum (check for free entry days/times), Museum Kampa (modern art), or the Franz Kafka Museum.\n",
            "*   **Lunch:** Enjoy a final budget-friendly vegetarian meal. Perhaps a hearty soup or some \"chlebíčky\" (open-faced sandwiches) from a local deli.\n",
            "*   **Afternoon:** Do some last-minute souvenir shopping (local markets often offer better prices) or revisit a favorite spot for a final photo.\n",
            "*   **Departure:** Head to the airport or train station using public transport.\n",
            "\n",
            "---\n",
            "\n",
            "Enjoy your budget-friendly and delicious vegetarian adventure in Prague!\n",
            "\n",
            "Conversation Summary (stored in state):\n",
            " The human states a preference for vegetarian food and budget-friendly options, which the AI acknowledges. The human then requests a 5-day trip, and the AI responds by providing a detailed 5-day budget-friendly vegetarian itinerary for Prague, Czech Republic, including accommodation tips, daily activities, and meal suggestions.\n"
          ]
        }
      ],
      "source": [
        "# Start from initial_state (or load a persisted state if you saved one)\n",
        "state = dict(initial_state)  # copy\n",
        "\n",
        "# Turn 1: user says they like vegetarian food\n",
        "state[\"user_message\"] = \"I like vegetarian food.\"\n",
        "state = app.invoke(state)  # app.invoke returns updated state\n",
        "print(\"\\n--- After Turn 1 ---\")\n",
        "print(\"Itinerary (partial):\\n\", state.get(\"itinerary\"))\n",
        "print(\"Summary:\\n\", state.get(\"conversation_summary\"))\n",
        "print(\"Trace entries:\", len(state.get(\"trace\", [])))\n",
        "\n",
        "# Turn 2: user says keep it budget-friendly\n",
        "state[\"user_message\"] = \"Keep it budget-friendly.\"\n",
        "state = app.invoke(state)\n",
        "print(\"\\n--- After Turn 2 ---\")\n",
        "print(\"Itinerary (partial):\\n\", state.get(\"itinerary\"))\n",
        "print(\"Summary:\\n\", state.get(\"conversation_summary\"))\n",
        "print(\"Trace entries:\", len(state.get(\"trace\", [])))\n",
        "\n",
        "# Turn 3: Ask for a 5-day trip\n",
        "state[\"user_message\"] = \"Recommend me a 5-day trip.\"\n",
        "state = app.invoke(state)\n",
        "print(\"\\n--- After Turn 3 (final) ---\")\n",
        "print(\"Final Itinerary:\\n\", state.get(\"itinerary\"))\n",
        "print(\"\\nConversation Summary (stored in state):\\n\", state.get(\"conversation_summary\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOLICBzCYSBm"
      },
      "source": [
        "Step 9 — Optional: Persist conversation_summary to disk (simple)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i00iUu8DYTYU",
        "outputId": "97ae5593-c323-42f9-93d0-99902f814fb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conversation summary saved to conversation_summary.json\n"
          ]
        }
      ],
      "source": [
        "# Save conversation_summary to disk so you can reload across notebook sessions\n",
        "import json\n",
        "\n",
        "summary_to_persist = state.get(\"conversation_summary\", \"\")\n",
        "with open(\"conversation_summary.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump({\"conversation_summary\": summary_to_persist}, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"Conversation summary saved to conversation_summary.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NX3s6vreYVVI"
      },
      "source": [
        "To reload next session:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "G9lvVi34YYqC"
      },
      "outputs": [],
      "source": [
        "# Load persisted summary (if any) before creating initial state\n",
        "with open(\"conversation_summary.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "initial_state[\"conversation_summary\"] = data.get(\"conversation_summary\", \"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iI4wmEc-YaUQ"
      },
      "source": [
        "Step 10 — Visualize the Graph (Mermaid) inside notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "scnzv3E1YgH0",
        "outputId": "7293d763-259d-453f-c160-5d68ebb085e6"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "```mermaid\n",
              "---\n",
              "config:\n",
              "  flowchart:\n",
              "    curve: linear\n",
              "---\n",
              "graph TD;\n",
              "\t__start__([<p>__start__</p>]):::first\n",
              "\tplanner(planner)\n",
              "\t__end__([<p>__end__</p>]):::last\n",
              "\t__start__ --> planner;\n",
              "\tplanner --> __end__;\n",
              "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
              "\tclassDef first fill-opacity:0\n",
              "\tclassDef last fill:#bfb6fc\n",
              "\n",
              "```"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# This is a lightweight visualization using LangGraph's mermaid drawing (may or may not render in some notebook viewers)\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "try:\n",
        "    mermaid = app.get_graph().draw_mermaid()\n",
        "    display(Markdown(\"```mermaid\\n\" + mermaid + \"\\n```\"))\n",
        "except Exception as e:\n",
        "    print(\"Graph visualization may not be supported in this environment:\", e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuoO9GpEYl-N"
      },
      "source": [
        "# Notes, caveats and production tips (short & actionable)\n",
        "\n",
        "**Why ConversationSummaryMemory?** It keeps memory compact by summarizing previous turns, which is ideal for a travel planner that only needs preferences (veg, budget, etc.) rather than full logs.\n",
        "\n",
        "**Persistence across sessions**: ConversationSummaryMemory is in-memory in this notebook. Persist the summary string (as shown) or use VectorStoreMemory for long-term persistent recall.\n",
        "\n",
        "**Validation**: Always validate memory content before acting (summaries can lose critical info). For critical apps add a “confirm preferences” step.\n",
        "\n",
        "**Privacy**: Avoid storing PII in plaintext. If you must, encrypt or store only hashed references.\n",
        "\n",
        "**Cost**: Memory + repeated LLM calls cost tokens — use summary + retrieval hybrid if costs grow.\n",
        "\n",
        "**Debugging**: Inspect state[\"trace\"] to see node runs and raw outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXhsLbfWYx6r"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
