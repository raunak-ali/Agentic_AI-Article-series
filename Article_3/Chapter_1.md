
# Chapter 1: Introduction & Tools (Article 3, Example Included)
---

## ğŸ”¹ 1. Introduction

In the last article, we built a simple one-node agent that could translate text into Shakespearean English. It worked, but it was also very limited. Why? Because in the real world, queries rarely stop at â€œjust generate text.â€  
Think about it:  
- â€œWhatâ€™s the population of Japan squared?â€ â†’ requires external knowledge (population data) + calculation.  
- â€œSummarize todayâ€™s top news on AI and write it in haiku form.â€ â†’ needs web search + reasoning + creative generation.  

A plain LLM agent canâ€™t handle this on its own. Thatâ€™s where tools come in. **Tools are what transform an LLM from a â€œchatbotâ€ into a true agent that can do things.**

---

## ğŸ”¹ 2. What Are Tools in LangChain?

In LangChain, tools are essentially functions or APIs that the LLM can call during its reasoning process.  
Instead of hallucinating a number or making up facts, the model can decide:  
â€œWait, I need to use a tool to get this right.â€

---

### Types of Tools

**Built-in tools:**  
- Python REPL (lets the agent execute Python code).  
- Calculator (quick math without needing to write code).

**API-based tools:**  
- Wikipedia search (fetch factual data).  
- SerpAPI (Google search results).  
- Any external REST API you wire up.

**Custom tools:**  
You can wrap your own function into a tool, e.g., a financial data fetcher, a database query, or even a business-specific calculator.

---

### Why Tools Matter

- **Accuracy** â†’ Tools reduce hallucinations by letting the agent fetch data instead of guessing.
- **Flexibility** â†’ You can extend your agent with any API relevant to your business or workflow.
- **Actionable AI** â†’ Instead of just producing text, the agent can actually perform tasks.

---

### Limitations & Trade-offs

Like everything, tools arenâ€™t free magic.

- **Latency** â†’ Each tool call adds extra round-trips. Imagine chaining multiple API calls inside one query.
- **Cost** â†’ More calls = higher usage costs if youâ€™re on paid APIs.
- **LLM Guidance** â†’ If the model isnâ€™t prompted well, it might overuse tools unnecessarily, slowing things down.

A good agent is one that knows **when to use a tool, and when not to**.

ğŸ“– Reference: [LangChain Tools Documentation](https://python.langchain.com/docs/integrations/tools/)

---

## ğŸ› ï¸ Tiny Example: Using a Calculator Tool in LangChain

Hereâ€™s a barebones example to make this real. Letâ€™s connect an LLM with a simple calculator tool:

```
# âœ… Install required libraries
!pip install -qU langchain langgraph langchain-google-genai

# âœ… Imports
import os
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.tools import PythonREPLTool
from langgraph.prebuilt import create_react_agent

# âœ… Set Google API Key
os.environ["GOOGLE_API_KEY"] = "YOUR_GOOGLE_API_KEY"

# âœ… Initialize LLM
llm = ChatGoogleGenerativeAI(model="gemini-pro")

# âœ… Define a tool (Python REPL acts like a calculator)
calculator = PythonREPLTool()

# âœ… Create a simple agent with the tool
agent = create_react_agent(llm, tools=[calculator])

# âœ… Run a test query
user_query = "What is 25 * 32?"
for s in agent.stream({"messages": [("user", user_query)]}):
    print(s)

```
â¡ï¸ Output:  
69104

This is the simplest taste of agents + tools in LangChain. The LLM doesnâ€™t â€œguessâ€ the multiplication; it decides to call the calculator tool, gets the result, and gives you the answer.

---

âœ… With this, weâ€™ve introduced the next big step: agents + tools.  
In the next chapter, weâ€™ll unpack the Reasoning Loop â€” how LangChain agents decide when to think, when to act, and when to stop.

---

